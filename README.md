# PPO-Missile-Guidance
This project uses the Proximal Policy Optimization (PPO) reinforcement learning algorithm to train an agent to dynamically optimize the proportional guidance coefficient in the missile guidance process. In the simulation environment of missile interception targets, the agent observes the relative states between the missile and the target (such as distance, approach speed, line of sight Angle, etc.) And output the key parameter in Proportional Navigation (PN) - Navigation Constant (N) as its action.

# Background of the problem
Missile precision guidance is one of the core challenges in the aerospace and defense fields. Proportional Navigation (PN) has become one of the most widely used classical guidance laws due to its clear principle, relatively simple implementation and good performance in many scenarios. The core of PN lies in its navigation constant (N), which directly determines the proportional relationship between the missile's normal acceleration command and the target's line-of-sight angular rate, and is crucial for guidance accuracy and energy efficiency.

# Core method
PPO + dynamic PN coefficient

# Key challenge
    
Traditional PN guidance faces two main challenges:

(1)Limitations of the fixed proportion coefficient (N) :

a.In actual complex interception scenarios (such as high speed, large maneuvering targets, and different initial conditions), a single fixed N value often fails to achieve optimal performance in all cases.

b. An excessively low N value may lead to slow response and a large number of off-targets. An excessively high N value may lead to unnecessary violent maneuvers, energy waste or even instability.

c.Ideally, the N value should be dynamically adjusted according to the combat situation (such as remaining time, relative speed, and the magnitude of the line of sight angular rate) to achieve accuracy, energy consumption, and robustness. Strike the best balance between the excellent qualities. It is extremely difficult to manually design such complex adaptive rules.

(2) Interference from sensor measurement noise:

a. The actual missile guidance system is inevitably affected by sensor noise. Distance measurement noise (such as radar ranging error) and Angle measurement noise (such as seeker's line-of-sight Angle error) are two of the most common and critical Gaussian noise sources.

b. These noises can contaminate the state information relied upon by the guidance system (such as the missile-target relative position, speed, and line-of-sight Angle), causing deviations in the guidance instructions calculated based on these noise states.

c. Traditional PN is relatively sensitive to noise. The performance of the fixed N value strategy may significantly decline under noise interference, and even lead to off-target.

# Simulation environment

# Model Description

Missile model

The particle model is adopted and the dynamics of three degrees of freedom (3DOF) is considered

The equation of motion includes the gravitational acceleration (g = [0, 0, -9.81] m/s²), acting in the vertical direction (Y).

The acceleration command is generated by proportional guidance (PN), and its core parameter, the navigation constant N, is dynamically output by the PPO agent

Target model

Designed as a compound maneuvering mode, it simulates real evasive behavior:

Phase 1 (Initial) : Uniform straight-line flight

Phase 2 (middle and later sections) : Perform the S-shaped serpentine maneuver

The lateral (XZ plane) acceleration varies according to the preset sine law



# State space

[dx,dy,dz,tgo,distance]

# Action space definition

N (The range can be adjusted according to the actual situation)

# Reward function design

Please refer to the get_reward() function in missile.py for specific implementation details and weight parameters.

# Noise model 

distance noise variance, Angle noise variance

Noise type: Additive White Gaussian Noise (AWGN)

Noise application object:

The relative distances of the three axes (dx, dy, dz

Mesh distance (R

Noise characteristics

The standard deviation (σ) of the noise is proportional to the current true bullet distance (R_true) 
 
# Usage Method

To train a new network: run MAPPO_MPE_main

test the pre-trained network: Run test.py

Output the reward function curve and hit probability curve during the training process: Open and run untitled2 in MATLAB

# Result

The result image can be found in the "images" folder

Among them, the reward curve is shown in Figure 7, the accuracy curve is shown in Figure 6, when the reward is negative, the minimum relative distance of the bullet is shown in Figure 8, the training state diagrams of the traditional proportional guidance algorithm are shown in Figures 9 to 10, and the training state diagrams of the PP-PN algorithm are shown in Figures 1 to 5
